{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2076717, 2)\n",
      "reset_index 완료\n",
      "input data shape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bin  label\n",
       "0  55      1\n",
       "1  89      0\n",
       "2  e5      0\n",
       "3  57      0\n",
       "4  56      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) 데이터로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 여러개 쳐도 나오게\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 파일읽기\n",
    "gcc3_3_32 = pd.read_csv(\"../data/binutils_gcc3~9_op0~4_csv/\"+'gcc3'+\"_3_32.csv\", index_col=0)\n",
    "\n",
    "# 형태 출력\n",
    "print(gcc3_3_32.shape)\n",
    "\n",
    "# reset_index (hex processing 하면서 값이 빠졌으니까 + n_gram 에서 index를 다루기 때문에)\n",
    "gcc3_3_32.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('reset_index 완료')\n",
    "print('input data shape')\n",
    "gcc3_3_32.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2076712</th>\n",
       "      <td>fc</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076713</th>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076714</th>\n",
       "      <td>ec</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076715</th>\n",
       "      <td>5d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076716</th>\n",
       "      <td>c3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bin  label\n",
       "2076712  fc      0\n",
       "2076713  89      0\n",
       "2076714  ec      0\n",
       "2076715  5d      0\n",
       "2076716  c3      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcc3_3_32.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "원핫인코딩완료\n",
      "(2076717, 257)\n",
      "0    2073836\n",
      "1       2881\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# (2-1) 데이터체크 - hex(16진수)가 256 label을 가져야 dummies 변환 가능 \n",
    "\n",
    "# 16진수 256개 종류가 있어서 pd.get_dummies 사용 가능.\n",
    "print(len(gcc3_3_32['bin'].unique()))\n",
    "\n",
    "# (3) get_dummies 변환 \n",
    "\n",
    "# 훈련데이터 (gcc 최적화버전 0, 1, 2, 3 one hot encoding)\n",
    "gcc3_3_32_onehot = pd.get_dummies(gcc3_3_32)\n",
    "\n",
    "\n",
    "print('원핫인코딩완료')\n",
    "\n",
    "print(gcc3_3_32_onehot.shape)\n",
    "\n",
    "# (4) 데이터 체크 - 1, 0 비율 ==> 1이 함수의 갯수를 뜻함\n",
    "# 정답 데이터 1, 0 비율 확인  ==> 1이 함수의 갯수를 뜻함\n",
    "print(gcc3_3_32_onehot['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20167\n",
      "20167\n",
      "20167\n",
      "0\n",
      "20167\n",
      "gcc3_3_32 20167\n"
     ]
    }
   ],
   "source": [
    "# (5-1) gcc3 6gram\n",
    "######################## \n",
    "idx3 = gcc3_3_32_onehot[gcc3_3_32_onehot['label']==1].index  # 407, 474 ...\n",
    "ls3 = list(idx3)\n",
    "\n",
    "# 최종 뽑을 행에 대한 index\n",
    "ls_idx3 = [] \n",
    "left_idx3, right_idx3 = 0, 7 # 3개씩\n",
    "\n",
    "# 6gram\n",
    "for k in range(left_idx3, right_idx3):\n",
    "    ls_idx3.extend(list(idx3 + k)) # index 형이라서 가능\n",
    "print(len(ls_idx3))\n",
    "\n",
    "#ls_idx3 = list(set(ls_idx3)) \n",
    "print(len(ls_idx3))\n",
    "\n",
    "ls_idx3.sort() # 인덱스 정렬\n",
    "\n",
    "# 1차 index 해당범위 초과한 것들 없애기\n",
    "ls_idx3 = list(filter(lambda x: x<len(gcc3_3_32_onehot), ls_idx3))\n",
    "print(len(ls_idx3))\n",
    "\n",
    "# 2차 남은 index들 중 right_idx3 나눈 나머지 없애기\n",
    "sub = len(ls_idx3)%(right_idx3)\n",
    "print(sub)\n",
    "\n",
    "ls_idx3 = ls_idx3[:len(ls_idx3)-sub]\n",
    "print(len(ls_idx3))\n",
    "\n",
    "print('gcc3_3_32', len(ls_idx3))\n",
    "\n",
    "# loc 로 수정필요\n",
    "gcc3_3_32_onehot_3gram = gcc3_3_32_onehot.loc[ls_idx3,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20167, 256) (20167,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터, 훈련 라벨\n",
    "x_gcc3_3_32_3 = gcc3_3_32_onehot_3gram.iloc[:,1:].to_numpy()\n",
    "y_gcc3_3_32_3 = gcc3_3_32_onehot_3gram['label'].to_numpy()\n",
    "print(x_gcc3_3_32_3.shape, y_gcc3_3_32_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2881, 7, 256) (2881, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "x_gcc3_3_32_3 = x_gcc3_3_32_3.reshape(-1, right_idx3, x_gcc3_3_32_3.shape[1])\n",
    "y_gcc3_3_32_3 = y_gcc3_3_32_3.reshape(-1, right_idx3, 1)\n",
    "\n",
    "print(x_gcc3_3_32_3.shape, y_gcc3_3_32_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 7, 32)             34944     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 7, 1)              33        \n",
      "=================================================================\n",
      "Total params: 34,977\n",
      "Trainable params: 34,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (10) 양방향 LSTM 모델링 작업\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import SimpleRNN, Input, Dense, LSTM\n",
    "from keras.layers import Bidirectional, TimeDistributed\n",
    "\n",
    "# 학습\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 3) # 조기종료 콜백함수 정의\n",
    "\n",
    "xInput = Input(batch_shape=(None,right_idx3, 256)) \n",
    "xBiLstm = Bidirectional(LSTM(16, return_sequences=True), merge_mode = 'concat')(xInput)\n",
    "xOutput = TimeDistributed(Dense(1, activation ='sigmoid'))(xBiLstm) # 각 스텝에서 cost가 전송되고, 오류가 다음 step으로 전송됨.\n",
    "\n",
    "model1 = Model(xInput, xOutput)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2592/2592 [==============================] - 2s 922us/step - loss: 0.4507 - accuracy: 0.8440\n",
      "Epoch 2/30\n",
      "2592/2592 [==============================] - 1s 195us/step - loss: 0.1615 - accuracy: 0.9344\n",
      "Epoch 3/30\n",
      "2592/2592 [==============================] - 1s 199us/step - loss: 0.0578 - accuracy: 0.9953\n",
      "Epoch 4/30\n",
      "2592/2592 [==============================] - 1s 196us/step - loss: 0.0279 - accuracy: 0.9952\n",
      "Epoch 5/30\n",
      "2592/2592 [==============================] - 1s 197us/step - loss: 0.0194 - accuracy: 0.9953\n",
      "Epoch 6/30\n",
      "2592/2592 [==============================] - 1s 199us/step - loss: 0.0146 - accuracy: 0.9960\n",
      "Epoch 7/30\n",
      "2592/2592 [==============================] - 1s 204us/step - loss: 0.0116 - accuracy: 0.9964\n",
      "Epoch 8/30\n",
      "2592/2592 [==============================] - 1s 197us/step - loss: 0.0093 - accuracy: 0.9965\n",
      "Epoch 9/30\n",
      "2592/2592 [==============================] - 1s 196us/step - loss: 0.0075 - accuracy: 0.9969\n",
      "Epoch 10/30\n",
      "2592/2592 [==============================] - 1s 199us/step - loss: 0.0063 - accuracy: 0.9970\n",
      "Epoch 11/30\n",
      "2592/2592 [==============================] - 1s 201us/step - loss: 0.0053 - accuracy: 0.9980\n",
      "Epoch 12/30\n",
      "2592/2592 [==============================] - 1s 202us/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 13/30\n",
      "2592/2592 [==============================] - 1s 195us/step - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 14/30\n",
      "2592/2592 [==============================] - 1s 198us/step - loss: 0.0038 - accuracy: 0.9983\n",
      "Epoch 15/30\n",
      "2592/2592 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.99 - 1s 199us/step - loss: 0.0033 - accuracy: 0.9985\n",
      "Epoch 16/30\n",
      "2592/2592 [==============================] - 0s 189us/step - loss: 0.0031 - accuracy: 0.9988\n",
      "Epoch 17/30\n",
      "2592/2592 [==============================] - 1s 199us/step - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 18/30\n",
      "2592/2592 [==============================] - 1s 198us/step - loss: 0.0027 - accuracy: 0.9996\n",
      "Epoch 19/30\n",
      "2592/2592 [==============================] - 0s 189us/step - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 20/30\n",
      "2592/2592 [==============================] - 1s 193us/step - loss: 0.0025 - accuracy: 0.9998\n",
      "Epoch 21/30\n",
      "2592/2592 [==============================] - 1s 204us/step - loss: 0.0024 - accuracy: 0.9996\n",
      "Epoch 22/30\n",
      "2592/2592 [==============================] - 1s 195us/step - loss: 0.0023 - accuracy: 0.9998\n",
      "Epoch 23/30\n",
      "2592/2592 [==============================] - 1s 194us/step - loss: 0.0022 - accuracy: 0.9998\n",
      "Epoch 24/30\n",
      "2592/2592 [==============================] - 1s 199us/step - loss: 0.0021 - accuracy: 0.9998\n",
      "Epoch 25/30\n",
      "2592/2592 [==============================] - 1s 195us/step - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 26/30\n",
      "2592/2592 [==============================] - 1s 195us/step - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 27/30\n",
      "2592/2592 [==============================] - 1s 196us/step - loss: 0.0018 - accuracy: 0.9998\n",
      "Epoch 28/30\n",
      "2592/2592 [==============================] - 1s 201us/step - loss: 0.0017 - accuracy: 0.9999\n",
      "Epoch 29/30\n",
      "2592/2592 [==============================] - 1s 195us/step - loss: 0.0016 - accuracy: 0.9999\n",
      "Epoch 30/30\n",
      "2592/2592 [==============================] - 1s 202us/step - loss: 0.0015 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e377aa88>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9995056846267919\n",
      "recall_score 0.9965635738831615\n",
      "precision_score 1.0\n",
      "f1_score 0.9982788296041308\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 0s 190us/step - loss: 0.0014 - accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 0.0012 - accuracy: 0.9999TA: 0s - loss: 5.1211e-04 - ac\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 1s 203us/step - loss: 9.7893e-04 - accuracy: 0.9998\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 9.1479e-04 - accuracy: 0.9999\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 8.6240e-04 - accuracy: 0.9998\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 8.1290e-04 - accuracy: 0.9999\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 7.7009e-04 - accuracy: 0.9999\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 7.3296e-04 - accuracy: 0.9998\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 6.6329e-04 - accuracy: 0.9999\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 6.1117e-04 - accuracy: 0.9999\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 5.9538e-04 - accuracy: 0.9999\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 5.6570e-04 - accuracy: 0.9999\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 0s 187us/step - loss: 5.1393e-04 - accuracy: 0.9999\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 5.0482e-04 - accuracy: 0.9999\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 4.7422e-04 - accuracy: 0.9999\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 4.0446e-04 - accuracy: 0.9999\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 0s 188us/step - loss: 3.5882e-04 - accuracy: 0.9999\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 0s 187us/step - loss: 3.3201e-04 - accuracy: 0.99990s - loss: 4.1790e-05 - \n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 3.0152e-04 - accuracy: 0.9999\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 2.6451e-04 - accuracy: 0.9999\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 0s 190us/step - loss: 2.6130e-04 - accuracy: 0.9999\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 2.3720e-04 - accuracy: 0.9999\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 0s 183us/step - loss: 2.6392e-04 - accuracy: 0.9999\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 2.1617e-04 - accuracy: 0.9999\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 0s 187us/step - loss: 1.7142e-04 - accuracy: 0.9999\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 0s 187us/step - loss: 1.4627e-04 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e3741348>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 0s 186us/step - loss: 1.5440e-04 - accuracy: 0.9999\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 1.2183e-04 - accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 1.0457e-04 - accuracy: 0.9999\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 9.0592e-05 - accuracy: 0.9999\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 8.4170e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 7.1276e-05 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 6.1253e-05 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 5.5702e-05 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 5.8699e-05 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 4.1365e-05 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 4.1239e-05 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 3.3429e-05 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 3.1457e-05 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - ETA: 0s - loss: 2.9382e-05 - accuracy: 1.00 - 1s 205us/step - loss: 2.8640e-05 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 2.2764e-05 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 2.0808e-05 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 2.0394e-05 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 1.6631e-05 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 1.5689e-05 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 1.4762e-05 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 1.1877e-05 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 1.0092e-05 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 9.6957e-06 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 8.2748e-06 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 0s 190us/step - loss: 7.4824e-06 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 6.7241e-06 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 5.4877e-06 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 5.2243e-06 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 4.4025e-06 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 3.6002e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e3741288>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 3.5833e-06 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 3.0622e-06 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 2.7970e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 2.3366e-06 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 224us/step - loss: 1.9755e-06 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 1.7309e-06 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 1.7554e-06 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 212us/step - loss: 1.3644e-06 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 1s 207us/step - loss: 1.2108e-06 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 1.1315e-06 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 1.0165e-06 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 8.1891e-07 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 8.1705e-07 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 1s 209us/step - loss: 7.1289e-07 - accuracy: 1.00000s - loss: 1.9153e-07 - \n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 5.8804e-07 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 5.2245e-07 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 5.0606e-07 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 1s 214us/step - loss: 4.1361e-07 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 4.3728e-07 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 3.5541e-07 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 3.0424e-07 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 0s 188us/step - loss: 2.6887e-07 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 2.5275e-07 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 2.5877e-07 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 2.1299e-07 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 1.9404e-07 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 1.6993e-07 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 1.5603e-07 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 1.5104e-07 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 207us/step - loss: 1.3264e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e3741388>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 1s 203us/step - loss: 1.3095e-07 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 1s 219us/step - loss: 1.1337e-07 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 207us/step - loss: 1.0337e-07 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 9.9539e-08 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 8.9621e-08 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 8.2307e-08 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 0s 187us/step - loss: 7.6208e-08 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 8.5490e-08 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 6.7507e-08 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 0s 188us/step - loss: 6.4650e-08 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 6.4109e-08 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 5.6495e-08 - accuracy: 1.00000s - loss: 7.4867e-08 - ac\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 5.4712e-08 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 0s 187us/step - loss: 5.1142e-08 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 4.7933e-08 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 4.5572e-08 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 4.5579e-08 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 4.0714e-08 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 3.9851e-08 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 3.7374e-08 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 3.6202e-08 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 3.4126e-08 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 3.3217e-08 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 3.1450e-08 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 3.1385e-08 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 2.8668e-08 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 1s 211us/step - loss: 2.8212e-08 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 2.6639e-08 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 2.5493e-08 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 2.4439e-08 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e209d808>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 1s 218us/step - loss: 2.1805e-08 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 2.1168e-08 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 208us/step - loss: 1.9624e-08 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 230us/step - loss: 1.9680e-08 - accuracy: 1.00000s - loss: 5.7653e-09 \n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 1.8232e-08 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 1.7871e-08 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 1.7500e-08 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 1.6682e-08 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 0s 190us/step - loss: 1.6012e-08 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 1.5529e-08 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 1.5191e-08 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 0s 187us/step - loss: 1.4459e-08 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 1.4094e-08 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 0s 186us/step - loss: 1.4144e-08 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 1.3372e-08 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 1.2909e-08 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 1.2892e-08 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 1.2321e-08 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 1.2025e-08 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 1.1681e-08 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 1s 197us/step - loss: 1.1681e-08 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 1.1116e-08 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 1.0784e-08 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 207us/step - loss: 1.0515e-08 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 1s 210us/step - loss: 1.0407e-08 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 1.0081e-08 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 9.8023e-09 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 9.7563e-09 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 9.4608e-09 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 9.3885e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e20a27c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 1s 203us/step - loss: 1.1181e-08 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 1s 203us/step - loss: 1.0873e-08 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 216us/step - loss: 1.0410e-08 - accuracy: 1.00000s - loss: 9.2147e-09 - \n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 9.7234e-09 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 203us/step - loss: 9.4443e-09 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 9.0141e-09 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 8.7547e-09 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 208us/step - loss: 8.7974e-09 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 8.1800e-09 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 8.3410e-09 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 7.9535e-09 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 7.7630e-09 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 1s 237us/step - loss: 7.5758e-09 - accuracy: 1.00000s - loss: 1.0384e-08 - accu\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 1s 423us/step - loss: 7.5528e-09 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 3s 1ms/step - loss: 7.3065e-09 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 296us/step - loss: 7.2179e-09 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 1s 238us/step - loss: 6.9486e-09 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 1s 259us/step - loss: 7.1029e-09 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 1s 231us/step - loss: 6.7220e-09 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 1s 219us/step - loss: 6.8008e-09 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 1s 214us/step - loss: 6.6892e-09 - accuracy: 1.00000s - loss: 6.0882e-09 - \n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 1s 248us/step - loss: 6.4396e-09 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 6.4626e-09 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 6.2885e-09 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - ETA: 0s - loss: 6.3424e-09 - accuracy: 1.00 - 1s 197us/step - loss: 6.1835e-09 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 6.2097e-09 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 5.9602e-09 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 6.0291e-09 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 5.8551e-09 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 5.7927e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e20a2c08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 8.1374e-09 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 0s 183us/step - loss: 7.7039e-09 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 7.6284e-09 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 209us/step - loss: 7.5036e-09 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 7.2507e-09 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 7.3427e-09 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 7.0176e-09 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 7.0077e-09 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 6.8238e-09 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 0s 190us/step - loss: 6.7384e-09 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 6.5316e-09 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 6.5513e-09 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 6.4363e-09 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 6.2557e-09 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 0s 186us/step - loss: 6.2196e-09 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 6.1375e-09 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 6.0357e-09 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 1s 225us/step - loss: 5.9799e-09 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 5.8616e-09 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 1s 203us/step - loss: 5.8321e-09 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 5.7204e-09 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 5.6449e-09 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 5.5891e-09 - accuracy: 1.00000s - loss: 7.1640e-09 - ac\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 5.5234e-09 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 5.4577e-09 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 5.4183e-09 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 1s 211us/step - loss: 5.2738e-09 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 5.2870e-09 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 5.1852e-09 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 208us/step - loss: 5.1031e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e209d708>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 4.7484e-09 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 4.6860e-09 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 215us/step - loss: 4.6171e-09 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 4.5842e-09 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 207us/step - loss: 4.5711e-09 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 4.4791e-09 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 1s 201us/step - loss: 4.4332e-09 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 4.3248e-09 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 4.3675e-09 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 4.3018e-09 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 4.2263e-09 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 4.1738e-09 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 4.1475e-09 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 1s 195us/step - loss: 4.1114e-09 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 0s 188us/step - loss: 4.0687e-09 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 4.0227e-09 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 1s 193us/step - loss: 3.9800e-09 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 3.9537e-09 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 1s 194us/step - loss: 3.9012e-09 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 3.8749e-09 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 3.7961e-09 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 1s 221us/step - loss: 3.7994e-09 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 205us/step - loss: 3.7731e-09 - accuracy: 1.00000s - loss: 5.3006e-09 - ac\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 3.7107e-09 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 0s 192us/step - loss: 3.7206e-09 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 1s 210us/step - loss: 3.6648e-09 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 3.6451e-09 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 3.6188e-09 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 1s 210us/step - loss: 3.5728e-09 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 3.5235e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e209d808>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 3.7797e-09 - accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 3.6910e-09 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "2593/2593 [==============================] - 1s 221us/step - loss: 3.6713e-09 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "2593/2593 [==============================] - 1s 211us/step - loss: 3.6615e-09 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "2593/2593 [==============================] - 1s 207us/step - loss: 3.6188e-09 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 3.5925e-09 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "2593/2593 [==============================] - 1s 203us/step - loss: 3.5564e-09 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "2593/2593 [==============================] - 1s 209us/step - loss: 3.5301e-09 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "2593/2593 [==============================] - 1s 204us/step - loss: 3.5367e-09 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 3.4743e-09 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 3.4447e-09 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "2593/2593 [==============================] - 1s 209us/step - loss: 3.4250e-09 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "2593/2593 [==============================] - 1s 208us/step - loss: 3.3594e-09 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "2593/2593 [==============================] - 1s 200us/step - loss: 3.3758e-09 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "2593/2593 [==============================] - 1s 206us/step - loss: 3.3462e-09 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 3.2937e-09 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "2593/2593 [==============================] - 1s 217us/step - loss: 3.2543e-09 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 3.2608e-09 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "2593/2593 [==============================] - 0s 189us/step - loss: 3.1984e-09 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "2593/2593 [==============================] - 1s 218us/step - loss: 3.1525e-09 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "2593/2593 [==============================] - 1s 198us/step - loss: 3.1722e-09 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 3.1131e-09 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 3.1393e-09 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "2593/2593 [==============================] - 1s 202us/step - loss: 3.0901e-09 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "2593/2593 [==============================] - 1s 196us/step - loss: 3.0441e-09 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "2593/2593 [==============================] - 0s 186us/step - loss: 3.0277e-09 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 2.9949e-09 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "2593/2593 [==============================] - 0s 191us/step - loss: 2.9719e-09 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "2593/2593 [==============================] - 0s 185us/step - loss: 2.9751e-09 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "2593/2593 [==============================] - 1s 199us/step - loss: 2.9160e-09 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x150e209d648>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "\n",
      "K-fold cross validation Accuracy: [0.9995056846267919, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "K-fold cross validation Recall: [0.9965635738831615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "K-fold cross validation Precision: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "\n",
      "K-fold cross validation F1-Score: [0.9982788296041308, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "########## 3gram\n",
    "\n",
    "# 교차검증 kfold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Accuracy, Precision, Recall, F1-Score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# Confusion Matrix, ROC Curve\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "# 최종 평가지표들 평균용\n",
    "accuracy, recall, precision, f1score, cm = [], [], [], [], []\n",
    "\n",
    "# 11. 교차검증 kfold - k.split - 10회 / K-Fold 객체 생성\n",
    "# kf = KFold(n_splits=10, shuffle=False, random_state=None) # KFold non shuffle 버전\n",
    "kf = KFold(n_splits=10, shuffle=False, random_state=None) # KFold non shuffle 버전\n",
    "\n",
    "for train, validation in kf.split(x_gcc3_3_32_3, y_gcc3_3_32_3):\n",
    "    print('======Training stage======')\n",
    "    model1.fit(x_gcc3_3_32_3[train],\n",
    "               y_gcc3_3_32_3[train],\n",
    "               epochs = 30,\n",
    "               batch_size = 32,\n",
    "               callbacks=[early_stopping])\n",
    "    #k_accuracy = '%.4f' %(model1.evaluate(data_10000x[validation], data_10000y[validation])[1])\n",
    "\n",
    "# 12. 교차검증결과 predict - 검증셋들\n",
    "    # predict 값\n",
    "    k_pr = model1.predict(x_gcc3_3_32_3[validation])\n",
    "    \n",
    "    # 테스트 predict 결과들 비교 (평가지표 보기위함)\n",
    "    pred = np.round(np.array(k_pr).flatten().tolist())\n",
    "    y_test = np.array(y_gcc3_3_32_3[validation]).flatten().tolist()\n",
    "    \n",
    "# 13. 평가지표들 출력\n",
    "    ## 평가지표들\n",
    "    k_accuracy = float(accuracy_score(y_test, pred))\n",
    "    k_recall =  float(recall_score(y_test, pred))\n",
    "    k_precision = float(precision_score(y_test, pred))\n",
    "    k_f1_score = float(f1_score(y_test, pred))\n",
    "    #k_cm = float(confusion_matrix(y_test, pred))\n",
    "    \n",
    "    print('accuracy_score', k_accuracy)\n",
    "    print('recall_score', k_recall)\n",
    "    print('precision_score', k_precision)\n",
    "    print('f1_score', k_f1_score)\n",
    "    #print('\\nconfusion_matrix\\n', k_cm)\n",
    "\n",
    "    accuracy.append(k_accuracy)\n",
    "    recall.append(k_recall)\n",
    "    precision.append(k_precision)\n",
    "    f1score.append(k_f1_score)\n",
    "    #cm.append(k_cm)\n",
    "#    print('roc_curve 면적', roc_auc_score(y_test, pred))\n",
    "\n",
    "# 14. 최종 결과지표\n",
    "print('\\nK-fold cross validation Accuracy: {}'.format(accuracy))\n",
    "print('\\nK-fold cross validation Recall: {}'.format(recall))\n",
    "print('\\nK-fold cross validation Precision: {}'.format(precision))\n",
    "print('\\nK-fold cross validation F1-Score: {}'.format(f1score))\n",
    "#print('\\nK-fold cross validation ConfusionMatrix: {}'.format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross_validation. Accuracy : 0.9999505684626792\n",
      "10-Fold Cross_validation. Recall : 0.9996563573883162\n",
      "10-Fold Cross_validation. Precision : 1.0\n",
      "10-Fold Cross_validation. F1-Score : 0.999827882960413\n"
     ]
    }
   ],
   "source": [
    "# 4gram 평가지표\n",
    "print('10-Fold Cross_validation. Accuracy :', np.mean(accuracy))\n",
    "print('10-Fold Cross_validation. Recall :', np.mean(recall))\n",
    "print('10-Fold Cross_validation. Precision :', np.mean(precision))\n",
    "print('10-Fold Cross_validation. F1-Score :', np.mean(f1score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
