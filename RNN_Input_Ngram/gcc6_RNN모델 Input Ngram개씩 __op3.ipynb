{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2329146, 2)\n",
      "reset_index 완료\n",
      "input data shape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  hex  bin\n",
       "0  55    1\n",
       "1  57    0\n",
       "2  56    0\n",
       "3  53    0\n",
       "4  e8    0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) 데이터로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 여러개 쳐도 나오게\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 파일읽기\n",
    "gcc6_3_32 = pd.read_csv(\"../data/binutils_gcc3~9_op0~4_csv/\"+'gcc6'+\"_3_32.csv\", index_col=0)\n",
    "\n",
    "# 형태 출력\n",
    "print(gcc6_3_32.shape)\n",
    "\n",
    "# reset_index (hex processing 하면서 값이 빠졌으니까 + n_gram 에서 index를 다루기 때문에)\n",
    "gcc6_3_32.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('reset_index 완료')\n",
    "print('input data shape')\n",
    "gcc6_3_32.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2329141</th>\n",
       "      <td>c3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329142</th>\n",
       "      <td>8b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329143</th>\n",
       "      <td>1c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329144</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329145</th>\n",
       "      <td>c3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hex  bin\n",
       "2329141  c3    0\n",
       "2329142  8b    1\n",
       "2329143  1c    0\n",
       "2329144  24    0\n",
       "2329145  c3    0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcc6_3_32.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "원핫인코딩완료\n",
      "(2329146, 257)\n",
      "0    2317594\n",
      "1      11552\n",
      "Name: bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# (2-1) 데이터체크 - hex(16진수)가 256 label을 가져야 dummies 변환 가능 \n",
    "\n",
    "# 16진수 256개 종류가 있어서 pd.get_dummies 사용 가능.\n",
    "print(len(gcc6_3_32['hex'].unique()))\n",
    "\n",
    "# (3) get_dummies 변환 \n",
    "\n",
    "# 훈련데이터 (gcc 최적화버전 0, 1, 2, 3 one hot encoding)\n",
    "gcc6_3_32_onehot = pd.get_dummies(gcc6_3_32)\n",
    "\n",
    "\n",
    "print('원핫인코딩완료')\n",
    "\n",
    "print(gcc6_3_32_onehot.shape)\n",
    "\n",
    "# (4) 데이터 체크 - 1, 0 비율 ==> 1이 함수의 갯수를 뜻함\n",
    "# 정답 데이터 1, 0 비율 확인  ==> 1이 함수의 갯수를 뜻함\n",
    "print(gcc6_3_32_onehot['bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>hex_00</th>\n",
       "      <th>hex_01</th>\n",
       "      <th>hex_02</th>\n",
       "      <th>hex_03</th>\n",
       "      <th>hex_04</th>\n",
       "      <th>hex_05</th>\n",
       "      <th>hex_06</th>\n",
       "      <th>hex_07</th>\n",
       "      <th>hex_08</th>\n",
       "      <th>...</th>\n",
       "      <th>hex_f6</th>\n",
       "      <th>hex_f7</th>\n",
       "      <th>hex_f8</th>\n",
       "      <th>hex_f9</th>\n",
       "      <th>hex_fa</th>\n",
       "      <th>hex_fb</th>\n",
       "      <th>hex_fc</th>\n",
       "      <th>hex_fd</th>\n",
       "      <th>hex_fe</th>\n",
       "      <th>hex_ff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2329136</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329137</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329139</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329140</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329141</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329142</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329143</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329144</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bin  hex_00  hex_01  hex_02  hex_03  hex_04  hex_05  hex_06  hex_07  \\\n",
       "2329136    0       0       0       0       0       0       0       0       0   \n",
       "2329137    0       0       0       0       0       0       0       0       0   \n",
       "2329138    0       0       0       0       0       0       0       0       0   \n",
       "2329139    0       0       0       0       0       0       0       0       0   \n",
       "2329140    0       0       0       0       0       0       0       0       0   \n",
       "2329141    0       0       0       0       0       0       0       0       0   \n",
       "2329142    1       0       0       0       0       0       0       0       0   \n",
       "2329143    0       0       0       0       0       0       0       0       0   \n",
       "2329144    0       0       0       0       0       0       0       0       0   \n",
       "2329145    0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "         hex_08  ...  hex_f6  hex_f7  hex_f8  hex_f9  hex_fa  hex_fb  hex_fc  \\\n",
       "2329136       0  ...       0       0       0       0       0       0       0   \n",
       "2329137       0  ...       0       0       0       0       0       0       0   \n",
       "2329138       0  ...       0       0       0       0       0       0       0   \n",
       "2329139       0  ...       0       0       0       0       0       0       0   \n",
       "2329140       0  ...       0       0       0       0       0       0       0   \n",
       "2329141       0  ...       0       0       0       0       0       0       0   \n",
       "2329142       0  ...       0       0       0       0       0       0       0   \n",
       "2329143       0  ...       0       0       0       0       0       0       0   \n",
       "2329144       0  ...       0       0       0       0       0       0       0   \n",
       "2329145       0  ...       0       0       0       0       0       0       0   \n",
       "\n",
       "         hex_fd  hex_fe  hex_ff  \n",
       "2329136       0       0       0  \n",
       "2329137       0       0       0  \n",
       "2329138       0       0       0  \n",
       "2329139       0       0       0  \n",
       "2329140       0       0       0  \n",
       "2329141       0       0       0  \n",
       "2329142       0       0       0  \n",
       "2329143       0       0       0  \n",
       "2329144       0       0       0  \n",
       "2329145       0       0       0  \n",
       "\n",
       "[10 rows x 257 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcc6_3_32_onehot.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80864\n",
      "80864\n",
      "80861\n",
      "4\n",
      "80857\n",
      "gcc6_3_32 80857\n"
     ]
    }
   ],
   "source": [
    "# (5-1) gcc3 6gram\n",
    "######################## \n",
    "idx3 = gcc6_3_32_onehot[gcc6_3_32_onehot['bin']==1].index  # 407, 474 ...\n",
    "ls3 = list(idx3)\n",
    "\n",
    "# 최종 뽑을 행에 대한 index\n",
    "ls_idx3 = [] \n",
    "left_idx3, right_idx3 = 0, 7 # 3개씩\n",
    "\n",
    "# 6gram\n",
    "for k in range(left_idx3, right_idx3):\n",
    "    ls_idx3.extend(list(idx3 + k)) # index 형이라서 가능\n",
    "print(len(ls_idx3))\n",
    "\n",
    "#ls_idx3 = list(set(ls_idx3)) \n",
    "print(len(ls_idx3))\n",
    "\n",
    "ls_idx3.sort() # 인덱스 정렬\n",
    "\n",
    "# 1차 index 해당범위 초과한 것들 없애기\n",
    "ls_idx3 = list(filter(lambda x: x<len(gcc6_3_32_onehot), ls_idx3))\n",
    "print(len(ls_idx3))\n",
    "\n",
    "# 2차 남은 index들 중 right_idx3 나눈 나머지 없애기\n",
    "sub = len(ls_idx3)%(right_idx3)\n",
    "print(sub)\n",
    "\n",
    "ls_idx3 = ls_idx3[:len(ls_idx3)-sub]\n",
    "print(len(ls_idx3))\n",
    "\n",
    "print('gcc6_3_32', len(ls_idx3))\n",
    "\n",
    "# loc 로 수정필요\n",
    "gcc6_3_32_onehot_3gram = gcc6_3_32_onehot.loc[ls_idx3,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80857, 256) (80857,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터, 훈련 라벨\n",
    "x_gcc6_3_32_3 = gcc6_3_32_onehot_3gram.iloc[:,1:].to_numpy()\n",
    "y_gcc6_3_32_3 = gcc6_3_32_onehot_3gram['bin'].to_numpy()\n",
    "print(x_gcc6_3_32_3.shape, y_gcc6_3_32_3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11551, 7, 256) (11551, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "x_gcc6_3_32_3 = x_gcc6_3_32_3.reshape(-1, right_idx3, x_gcc6_3_32_3.shape[1])\n",
    "y_gcc6_3_32_3 = y_gcc6_3_32_3.reshape(-1, right_idx3, 1)\n",
    "\n",
    "print(x_gcc6_3_32_3.shape, y_gcc6_3_32_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 7, 32)             34944     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 7, 1)              33        \n",
      "=================================================================\n",
      "Total params: 34,977\n",
      "Trainable params: 34,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (10) 양방향 LSTM 모델링 작업\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import SimpleRNN, Input, Dense, LSTM\n",
    "from keras.layers import Bidirectional, TimeDistributed\n",
    "\n",
    "# 학습\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 3) # 조기종료 콜백함수 정의\n",
    "\n",
    "xInput = Input(batch_shape=(None,right_idx3, 256)) \n",
    "xBiLstm = Bidirectional(LSTM(16, return_sequences=True), merge_mode = 'concat')(xInput)\n",
    "xOutput = TimeDistributed(Dense(1, activation ='sigmoid'))(xBiLstm) # 각 스텝에서 cost가 전송되고, 오류가 다음 step으로 전송됨.\n",
    "\n",
    "model1 = Model(xInput, xOutput)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10395/10395 [==============================] - 2s 209us/step - loss: 0.2051 - accuracy: 0.9261\n",
      "Epoch 2/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0345 - accuracy: 0.9890\n",
      "Epoch 3/30\n",
      "10395/10395 [==============================] - 2s 153us/step - loss: 0.0244 - accuracy: 0.9934\n",
      "Epoch 4/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0178 - accuracy: 0.9955\n",
      "Epoch 5/30\n",
      "10395/10395 [==============================] - 2s 151us/step - loss: 0.0136 - accuracy: 0.9966\n",
      "Epoch 6/30\n",
      "10395/10395 [==============================] - 2s 153us/step - loss: 0.0118 - accuracy: 0.9970\n",
      "Epoch 7/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0105 - accuracy: 0.9973\n",
      "Epoch 8/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 9/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0089 - accuracy: 0.9976\n",
      "Epoch 10/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0086 - accuracy: 0.9978\n",
      "Epoch 11/30\n",
      "10395/10395 [==============================] - 2s 153us/step - loss: 0.0080 - accuracy: 0.9979\n",
      "Epoch 12/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 13/30\n",
      "10395/10395 [==============================] - 2s 149us/step - loss: 0.0075 - accuracy: 0.9981\n",
      "Epoch 14/30\n",
      "10395/10395 [==============================] - 2s 149us/step - loss: 0.0072 - accuracy: 0.9981\n",
      "Epoch 15/30\n",
      "10395/10395 [==============================] - 2s 151us/step - loss: 0.0068 - accuracy: 0.9983\n",
      "Epoch 16/30\n",
      "10395/10395 [==============================] - 2s 150us/step - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 17/30\n",
      "10395/10395 [==============================] - 2s 150us/step - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 18/30\n",
      "10395/10395 [==============================] - 2s 149us/step - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 19/30\n",
      "10395/10395 [==============================] - 2s 150us/step - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 20/30\n",
      "10395/10395 [==============================] - 2s 154us/step - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 21/30\n",
      "10395/10395 [==============================] - 2s 159us/step - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 22/30\n",
      "10395/10395 [==============================] - 2s 155us/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 23/30\n",
      "10395/10395 [==============================] - 2s 150us/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 24/30\n",
      "10395/10395 [==============================] - 2s 149us/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 25/30\n",
      "10395/10395 [==============================] - 2s 150us/step - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 26/30\n",
      "10395/10395 [==============================] - 2s 152us/step - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 27/30\n",
      "10395/10395 [==============================] - 2s 157us/step - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 28/30\n",
      "10395/10395 [==============================] - 2s 164us/step - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 29/30\n",
      "10395/10395 [==============================] - 2s 156us/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 30/30\n",
      "10395/10395 [==============================] - 2s 160us/step - loss: 0.0043 - accuracy: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282de341e48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9922145328719724\n",
      "recall_score 0.9648\n",
      "precision_score 0.9844897959183674\n",
      "f1_score 0.9745454545454545\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 2s 156us/step - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 2s 159us/step - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 2s 153us/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 2s 181us/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 2s 184us/step - loss: 0.0050 - accuracy: 0.9987\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 2s 183us/step - loss: 0.0048 - accuracy: 0.9988\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 2s 181us/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 2s 181us/step - loss: 0.0044 - accuracy: 0.9989\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 2s 180us/step - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 2s 179us/step - loss: 0.0042 - accuracy: 0.9991\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 2s 181us/step - loss: 0.0039 - accuracy: 0.9991\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 2s 185us/step - loss: 0.0038 - accuracy: 0.9992\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 2s 185us/step - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 2s 180us/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 2s 182us/step - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 2s 185us/step - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 2s 201us/step - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 2s 208us/step - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 2s 209us/step - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 2s 213us/step - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 2s 208us/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 2s 212us/step - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 2s 206us/step - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 2s 216us/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 2s 217us/step - loss: 0.0026 - accuracy: 0.9994\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 2s 211us/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 2s 207us/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 2s 211us/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 2s 213us/step - loss: 0.0023 - accuracy: 0.9995\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 0.0022 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282e07b0508>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9956709956709957\n",
      "recall_score 0.9807370184254607\n",
      "precision_score 0.9898562975486053\n",
      "f1_score 0.985275557425326\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 3s 254us/step - loss: 0.0035 - accuracy: 0.9992\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 3s 245us/step - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 3s 248us/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 3s 252us/step - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 3s 249us/step - loss: 0.0021 - accuracy: 0.9996\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 3s 252us/step - loss: 0.0019 - accuracy: 0.9996\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 3s 257us/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 3s 293us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 3s 312us/step - loss: 0.0017 - accuracy: 0.99970s - loss: 0.0018 - ac\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 3s 302us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 3s 282us/step - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 3s 293us/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 3s 286us/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 3s 292us/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 3s 294us/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 3s 317us/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 3s 320us/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 3s 318us/step - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 3s 314us/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 3s 314us/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 3s 304us/step - loss: 0.0013 - accuracy: 0.9998\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 3s 334us/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 4s 337us/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 4s 344us/step - loss: 0.0012 - accuracy: 0.99980s - loss: 0.0011 - \n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 4s 345us/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 3s 334us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 4s 348us/step - loss: 0.0011 - accuracy: 0.99980s - los\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 4s 361us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 3s 335us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 3s 332us/step - loss: 0.0012 - accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282e07b0348>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9965367965367965\n",
      "recall_score 0.9913928012519562\n",
      "precision_score 0.9867601246105919\n",
      "f1_score 0.9890710382513661\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 4s 347us/step - loss: 0.0025 - accuracy: 0.99940s - loss: 0.0024 - accuracy - ETA: 0s - loss: 0.0024 - accu\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 4s 349us/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 4s 340us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 4s 356us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 4s 348us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 4s 350us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 4s 350us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 4s 346us/step - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 4s 339us/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 3s 325us/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 3s 334us/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 4s 342us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 4s 338us/step - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 4s 357us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 4s 347us/step - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 4s 344us/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 4s 352us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 4s 357us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 4s 355us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 4s 379us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 4s 398us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 4s 349us/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 3s 336us/step - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 4s 348us/step - loss: 0.0012 - accuracy: 0.99980s - loss: 0\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 3s 331us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 4s 339us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 4s 347us/step - loss: 0.0010 - accuracy: 0.9998\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 3s 330us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 4s 343us/step - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 3s 333us/step - loss: 0.0011 - accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282e07b0048>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9992578849721707\n",
      "recall_score 0.9974662162162162\n",
      "precision_score 0.9974662162162162\n",
      "f1_score 0.9974662162162162\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 4s 340us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 4s 362us/step - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 4s 367us/step - loss: 9.9951e-04 - accuracy: 0.9998\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 4s 354us/step - loss: 9.5515e-04 - accuracy: 0.9998\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 4s 341us/step - loss: 9.2500e-04 - accuracy: 0.9998\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 3s 334us/step - loss: 9.5807e-04 - accuracy: 0.9998\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 3s 287us/step - loss: 9.6666e-04 - accuracy: 0.9998\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 3s 281us/step - loss: 8.9648e-04 - accuracy: 0.9998\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 3s 293us/step - loss: 9.0240e-04 - accuracy: 0.9998\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 3s 308us/step - loss: 8.8617e-04 - accuracy: 0.9998\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 3s 294us/step - loss: 8.8927e-04 - accuracy: 0.9998\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 3s 285us/step - loss: 8.7517e-04 - accuracy: 0.9998\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 3s 285us/step - loss: 8.3118e-04 - accuracy: 0.9998\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 3s 286us/step - loss: 8.8193e-04 - accuracy: 0.9998\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 7.7748e-04 - accuracy: 0.9998\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 7.9429e-04 - accuracy: 0.9998\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 7.5359e-04 - accuracy: 0.9998\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 7.6252e-04 - accuracy: 0.9998\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - ETA: 0s - loss: 7.7268e-04 - accuracy: 0.99 - 2s 234us/step - loss: 7.6826e-04 - accuracy: 0.9998\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 7.7925e-04 - accuracy: 0.9998\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 8.5422e-04 - accuracy: 0.9998\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 7.3247e-04 - accuracy: 0.9998\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 7.6430e-04 - accuracy: 0.9998\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 7.6325e-04 - accuracy: 0.9998\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 7.0616e-04 - accuracy: 0.9998\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 6.7295e-04 - accuracy: 0.9998\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 7.4425e-04 - accuracy: 0.9998\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 6.7215e-04 - accuracy: 0.9998\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 6.8070e-04 - accuracy: 0.9998\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 6.2653e-04 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282e07b0e48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9985157699443413\n",
      "recall_score 0.9967715899919289\n",
      "precision_score 0.9935639581657281\n",
      "f1_score 0.9951651893634165\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 8.9009e-04 - accuracy: 0.9998\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 9.2216e-04 - accuracy: 0.9998\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 2s 235us/step - loss: 8.2357e-04 - accuracy: 0.9998\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 7.4865e-04 - accuracy: 0.9998\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 7.8927e-04 - accuracy: 0.9998\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 7.6706e-04 - accuracy: 0.9998\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 6.9138e-04 - accuracy: 0.9999\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 7.8466e-04 - accuracy: 0.9998\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 7.6958e-04 - accuracy: 0.9998\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 6.9876e-04 - accuracy: 0.9999\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 6.8700e-04 - accuracy: 0.9999\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 6.7078e-04 - accuracy: 0.9998\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 7.2102e-04 - accuracy: 0.9999\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 6.9363e-04 - accuracy: 0.9999\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 6.4598e-04 - accuracy: 0.9998\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 5.8981e-04 - accuracy: 0.9999\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 6.2000e-04 - accuracy: 0.9999\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 6.1186e-04 - accuracy: 0.9999\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 6.3978e-04 - accuracy: 0.9998\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 6.9599e-04 - accuracy: 0.9998\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 6.8811e-04 - accuracy: 0.9998\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 6.2522e-04 - accuracy: 0.9999\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 2s 235us/step - loss: 6.1049e-04 - accuracy: 0.9999\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 6.5689e-04 - accuracy: 0.9999\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 5.8859e-04 - accuracy: 0.9999\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 2s 235us/step - loss: 6.0041e-04 - accuracy: 0.9999\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 5.5726e-04 - accuracy: 0.9999\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 5.7479e-04 - accuracy: 0.9999\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 5.5900e-04 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282de5c1d08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 6.0190e-04 - accuracy: 0.9999\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 5.2757e-04 - accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 5.5803e-04 - accuracy: 0.9999\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 5.0863e-04 - accuracy: 0.9999\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 5.6580e-04 - accuracy: 0.9999\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 5.0589e-04 - accuracy: 0.9999\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 5.3466e-04 - accuracy: 0.9999\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 2s 228us/step - loss: 5.1053e-04 - accuracy: 0.9999\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 5.1439e-04 - accuracy: 0.9999\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 5.0066e-04 - accuracy: 0.9999\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 5.5046e-04 - accuracy: 0.9999\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 5.0638e-04 - accuracy: 0.9999\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 5.8435e-04 - accuracy: 0.9999\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 5.0948e-04 - accuracy: 0.9999\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 4.9928e-04 - accuracy: 0.9999\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 4.8719e-04 - accuracy: 0.9999\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 4.5716e-04 - accuracy: 0.9999\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 5.0208e-04 - accuracy: 0.9999\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 4.6263e-04 - accuracy: 0.9999\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 4.5033e-04 - accuracy: 0.9999\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 4.6191e-04 - accuracy: 0.9999\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 4.1790e-04 - accuracy: 0.9999\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 4.4949e-04 - accuracy: 0.9999\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 4.4619e-04 - accuracy: 0.9999\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 4.2724e-04 - accuracy: 0.9999\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 4.7729e-04 - accuracy: 0.9999\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 4.5013e-04 - accuracy: 0.9999\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 4.5728e-04 - accuracy: 0.9999\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 4.3720e-04 - accuracy: 0.9999\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 3.8159e-04 - accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282de5c45c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 1.0\n",
      "recall_score 1.0\n",
      "precision_score 1.0\n",
      "f1_score 1.0\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 2.7773e-04 - accuracy: 0.9999\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 2.3010e-04 - accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 2.4707e-04 - accuracy: 0.9999\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 2.7471e-04 - accuracy: 0.9999\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 2.1076e-04 - accuracy: 0.9999\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 2.5224e-04 - accuracy: 0.9999\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 2.6142e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 2s 235us/step - loss: 2.3358e-04 - accuracy: 0.9999\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 2.2247e-04 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 2.1981e-04 - accuracy: 0.9999\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 2.3637e-04 - accuracy: 0.9999\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 2.3756e-04 - accuracy: 0.9999\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 2.6864e-04 - accuracy: 0.9999\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 2.3471e-04 - accuracy: 0.9999\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 3.1271e-04 - accuracy: 0.9999\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 2.4509e-04 - accuracy: 0.9999\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 2.2624e-04 - accuracy: 0.9999\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 2s 228us/step - loss: 2.2152e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 2.0120e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - ETA: 0s - loss: 2.3616e-04 - accuracy: 0.99 - 2s 233us/step - loss: 2.3481e-04 - accuracy: 0.9999\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 2.0714e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 1.9426e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 2.2099e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 2s 227us/step - loss: 2.4158e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 2.1247e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 2.1934e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 2.2008e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 1.9655e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 2.7126e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 1.6637e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282de5c77c8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9996289424860854\n",
      "recall_score 0.9974048442906575\n",
      "precision_score 1.0\n",
      "f1_score 0.9987007362494587\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - ETA: 0s - loss: 4.9649e-04 - accuracy: 0.99 - 2s 231us/step - loss: 4.9515e-04 - accuracy: 0.9999\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 3.2826e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 3.4014e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 3.1660e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 3.3103e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 3.3681e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 3.4268e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 2s 235us/step - loss: 3.3804e-04 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 3.4701e-04 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 3.1001e-04 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 3.5563e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 2s 240us/step - loss: 3.3120e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 3.4663e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 3s 241us/step - loss: 3.3007e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 3.3927e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 3.2419e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 3.4293e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 3.3054e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 3.4758e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 3.4066e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 3.1170e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 3.3261e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 3.3398e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 3s 241us/step - loss: 3.5955e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 3s 244us/step - loss: 3.4567e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 3s 248us/step - loss: 3.2978e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 3s 247us/step - loss: 3.3509e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 3.1879e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 3s 243us/step - loss: 3.3153e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 2s 237us/step - loss: 3.3446e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282de5c7308>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9996289424860854\n",
      "recall_score 0.9991645781119465\n",
      "precision_score 0.998330550918197\n",
      "f1_score 0.9987473903966597\n",
      "======Training stage======\n",
      "Epoch 1/30\n",
      "10396/10396 [==============================] - 3s 242us/step - loss: 5.3347e-04 - accuracy: 0.9999\n",
      "Epoch 2/30\n",
      "10396/10396 [==============================] - 3s 263us/step - loss: 5.0691e-04 - accuracy: 0.9999\n",
      "Epoch 3/30\n",
      "10396/10396 [==============================] - 2s 235us/step - loss: 4.6739e-04 - accuracy: 0.9999\n",
      "Epoch 4/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 4.7805e-04 - accuracy: 0.9999\n",
      "Epoch 5/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 4.2914e-04 - accuracy: 0.9999\n",
      "Epoch 6/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 4.9170e-04 - accuracy: 0.9999\n",
      "Epoch 7/30\n",
      "10396/10396 [==============================] - 2s 229us/step - loss: 4.5416e-04 - accuracy: 0.9999\n",
      "Epoch 8/30\n",
      "10396/10396 [==============================] - 2s 231us/step - loss: 4.6464e-04 - accuracy: 0.9999\n",
      "Epoch 9/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 3.8179e-04 - accuracy: 0.9999\n",
      "Epoch 10/30\n",
      "10396/10396 [==============================] - 2s 230us/step - loss: 4.3765e-04 - accuracy: 0.9999\n",
      "Epoch 11/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 4.5731e-04 - accuracy: 0.9999\n",
      "Epoch 12/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 4.1503e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "10396/10396 [==============================] - 2s 237us/step - loss: 4.0249e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 4.7474e-04 - accuracy: 0.9999\n",
      "Epoch 15/30\n",
      "10396/10396 [==============================] - 2s 232us/step - loss: 4.0243e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "10396/10396 [==============================] - 2s 233us/step - loss: 3.8645e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 4.1990e-04 - accuracy: 0.9999\n",
      "Epoch 18/30\n",
      "10396/10396 [==============================] - 3s 248us/step - loss: 3.8744e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "10396/10396 [==============================] - 3s 241us/step - loss: 3.7030e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 4.0839e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 3.7637e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "10396/10396 [==============================] - 2s 235us/step - loss: 3.9793e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "10396/10396 [==============================] - 2s 238us/step - loss: 3.2409e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "10396/10396 [==============================] - 2s 236us/step - loss: 3.7460e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "10396/10396 [==============================] - 2s 237us/step - loss: 3.8790e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "10396/10396 [==============================] - 2s 237us/step - loss: 3.6684e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "10396/10396 [==============================] - 2s 240us/step - loss: 4.0618e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "10396/10396 [==============================] - 3s 243us/step - loss: 3.3876e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "10396/10396 [==============================] - 2s 237us/step - loss: 3.9210e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "10396/10396 [==============================] - 2s 234us/step - loss: 3.5353e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x282de5c7348>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9995052566481137\n",
      "recall_score 0.9968178202068417\n",
      "precision_score 1.0\n",
      "f1_score 0.9984063745019921\n",
      "\n",
      "K-fold cross validation Accuracy: [0.9922145328719724, 0.9956709956709957, 0.9965367965367965, 0.9992578849721707, 0.9985157699443413, 1.0, 1.0, 0.9996289424860854, 0.9996289424860854, 0.9995052566481137]\n",
      "\n",
      "K-fold cross validation Recall: [0.9648, 0.9807370184254607, 0.9913928012519562, 0.9974662162162162, 0.9967715899919289, 1.0, 1.0, 0.9974048442906575, 0.9991645781119465, 0.9968178202068417]\n",
      "\n",
      "K-fold cross validation Precision: [0.9844897959183674, 0.9898562975486053, 0.9867601246105919, 0.9974662162162162, 0.9935639581657281, 1.0, 1.0, 1.0, 0.998330550918197, 1.0]\n",
      "\n",
      "K-fold cross validation F1-Score: [0.9745454545454545, 0.985275557425326, 0.9890710382513661, 0.9974662162162162, 0.9951651893634165, 1.0, 1.0, 0.9987007362494587, 0.9987473903966597, 0.9984063745019921]\n"
     ]
    }
   ],
   "source": [
    "########## 3gram\n",
    "\n",
    "# 교차검증 kfold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Accuracy, Precision, Recall, F1-Score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# Confusion Matrix, ROC Curve\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "# 최종 평가지표들 평균용\n",
    "accuracy, recall, precision, f1score, cm = [], [], [], [], []\n",
    "\n",
    "# 11. 교차검증 kfold - k.split - 10회 / K-Fold 객체 생성\n",
    "# kf = KFold(n_splits=10, shuffle=False, random_state=None) # KFold non shuffle 버전\n",
    "kf = KFold(n_splits=10, shuffle=False, random_state=None) # KFold non shuffle 버전\n",
    "\n",
    "for train, validation in kf.split(x_gcc6_3_32_3, y_gcc6_3_32_3):\n",
    "    print('======Training stage======')\n",
    "    model1.fit(x_gcc6_3_32_3[train],\n",
    "               y_gcc6_3_32_3[train],\n",
    "               epochs = 30,\n",
    "               batch_size = 32,\n",
    "               callbacks=[early_stopping])\n",
    "    #k_accuracy = '%.4f' %(model1.evaluate(data_10000x[validation], data_10000y[validation])[1])\n",
    "\n",
    "# 12. 교차검증결과 predict - 검증셋들\n",
    "    # predict 값\n",
    "    k_pr = model1.predict(x_gcc6_3_32_3[validation])\n",
    "    \n",
    "    # 테스트 predict 결과들 비교 (평가지표 보기위함)\n",
    "    pred = np.round(np.array(k_pr).flatten().tolist())\n",
    "    y_test = np.array(y_gcc6_3_32_3[validation]).flatten().tolist()\n",
    "    \n",
    "# 13. 평가지표들 출력\n",
    "    ## 평가지표들\n",
    "    k_accuracy = float(accuracy_score(y_test, pred))\n",
    "    k_recall =  float(recall_score(y_test, pred))\n",
    "    k_precision = float(precision_score(y_test, pred))\n",
    "    k_f1_score = float(f1_score(y_test, pred))\n",
    "    #k_cm = float(confusion_matrix(y_test, pred))\n",
    "    \n",
    "    print('accuracy_score', k_accuracy)\n",
    "    print('recall_score', k_recall)\n",
    "    print('precision_score', k_precision)\n",
    "    print('f1_score', k_f1_score)\n",
    "    #print('\\nconfusion_matrix\\n', k_cm)\n",
    "\n",
    "    accuracy.append(k_accuracy)\n",
    "    recall.append(k_recall)\n",
    "    precision.append(k_precision)\n",
    "    f1score.append(k_f1_score)\n",
    "    #cm.append(k_cm)\n",
    "#    print('roc_curve 면적', roc_auc_score(y_test, pred))\n",
    "\n",
    "# 14. 최종 결과지표\n",
    "print('\\nK-fold cross validation Accuracy: {}'.format(accuracy))\n",
    "print('\\nK-fold cross validation Recall: {}'.format(recall))\n",
    "print('\\nK-fold cross validation Precision: {}'.format(precision))\n",
    "print('\\nK-fold cross validation F1-Score: {}'.format(f1score))\n",
    "#print('\\nK-fold cross validation ConfusionMatrix: {}'.format(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross_validation. Accuracy : 0.998095912161656\n",
      "10-Fold Cross_validation. Recall : 0.9924554868495006\n",
      "10-Fold Cross_validation. Precision : 0.9950466943377705\n",
      "10-Fold Cross_validation. F1-Score : 0.993737795694989\n"
     ]
    }
   ],
   "source": [
    "# 4gram 평가지표\n",
    "print('10-Fold Cross_validation. Accuracy :', np.mean(accuracy))\n",
    "print('10-Fold Cross_validation. Recall :', np.mean(recall))\n",
    "print('10-Fold Cross_validation. Precision :', np.mean(precision))\n",
    "print('10-Fold Cross_validation. F1-Score :', np.mean(f1score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
