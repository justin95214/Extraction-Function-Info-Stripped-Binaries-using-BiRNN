{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모델 N-Byte 방식 (함수정보 포함 vs 미포함 => 1:1 비율)\n",
    "\n",
    "## (1) 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33250757, 2)\n",
      "shape - (33250757, 2)\n",
      "reset_index 완료\n",
      "input data shape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin  label\n",
       "0   47      0\n",
       "1  108      0\n",
       "2  105      0\n",
       "3   98      0\n",
       "4   47      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) 데이터로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 여러개 쳐도 나오게\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 파일읽기\n",
    "bin6_3 = pd.read_csv(\"../../바이너리_최종데이터_1004/gcc6/o3/o3_bincore6.csv\", index_col=0)\n",
    "print(bin6_3.shape)\n",
    "\n",
    "# reset_index (hex processing 하면서 값이 빠졌으니까 + n_gram 에서 index를 다루기 때문에)\n",
    "bin6_3.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('shape -', bin6_3.shape)\n",
    "print('reset_index 완료')\n",
    "print('input data shape')\n",
    "bin6_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "0    33215560\n",
      "1       35197\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# (2-1) 데이터체크 1 - hex(16진수)가 256 label을 가져야 dummies 변환 가능 \n",
    "# 16진수 256개 종류가 있어서 pd.get_dummies 사용 가능.\n",
    "print(len(bin6_3['bin'].unique()))\n",
    "\n",
    "# (2-2) 데이터 체크 2 - 1, 0 비율 ==> 1이 함수의 갯수를 뜻함\n",
    "# 정답 데이터 1, 0 비율 확인  ==> 1이 함수의 갯수를 뜻함\n",
    "print(bin6_3['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) N Byte씩 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689456\n",
      "나머지 0\n",
      "최종 길이 1689456\n",
      "bin6_3 1689456\n"
     ]
    }
   ],
   "source": [
    "idx_bin = bin6_3[bin6_3['label']==1].index  # 407, 474 ...\n",
    "ls_bin = list(idx_bin)\n",
    "\n",
    "# 최종 뽑을 행에 대한 index\n",
    "ls_idx_bin = []\n",
    "\n",
    "# n byte 자르기 방식\n",
    "left_idx, right_idx = 0, 48 # 3개씩\n",
    "\n",
    "# n byte 자르기\n",
    "for k in range(left_idx, right_idx):\n",
    "    ls_idx_bin.extend(list(idx_bin + k)) # index 형이라서 가능\n",
    "\n",
    "#ls_idx = list(set(ls_idx)) \n",
    "ls_idx_bin.sort() # 인덱스 정렬\n",
    "\n",
    "# 1차 index 해당범위 초과한 것들 없애기\n",
    "ls_idx_bin = list(filter(lambda x: x<len(bin6_3), ls_idx_bin))\n",
    "print(len(ls_idx_bin))\n",
    "\n",
    "# 2차 남은 index들 중 right_idx 나눈 나머지 없애기\n",
    "sub_bin = len(ls_idx_bin)%(right_idx)\n",
    "print('나머지', sub_bin)\n",
    "\n",
    "ls_idx_bin = ls_idx_bin[:len(ls_idx_bin)-sub_bin]\n",
    "print('최종 길이', len(ls_idx_bin))\n",
    "\n",
    "print('bin6_3', len(ls_idx_bin))\n",
    "\n",
    "# loc 로 수정필요\n",
    "bin6_3_Ngram = bin6_3.loc[ls_idx_bin,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) false data 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35197.0\n",
      "0 32619509\n",
      "1000 17111355\n",
      "2000 1883239\n",
      "3000 20418578\n",
      "4000 29796258\n",
      "5000 29167798\n",
      "6000 2613414\n",
      "7000 32913097\n",
      "8000 27686346\n",
      "9000 12948157\n",
      "10000 1359289\n",
      "11000 2447120\n",
      "12000 22223930\n",
      "13000 15658705\n",
      "14000 16677322\n",
      "15000 23498375\n",
      "16000 4464904\n",
      "17000 2721763\n",
      "18000 8770025\n",
      "19000 16656991\n",
      "20000 20322473\n",
      "21000 29821849\n",
      "22000 19001191\n",
      "23000 19664037\n",
      "24000 25055171\n",
      "25000 25594889\n",
      "26000 27463442\n",
      "27000 25502812\n",
      "28000 660702\n",
      "29000 20859568\n",
      "30000 8469083\n",
      "31000 13094070\n",
      "32000 2216084\n",
      "33000 18923157\n",
      "34000 20176735\n",
      "35000 11334574\n",
      "완료\n",
      "35197\n"
     ]
    }
   ],
   "source": [
    "# false data 만들기 - False 데이터 랜덤 생성\n",
    "\n",
    "# 목표치\n",
    "goal_bin = len(bin6_3_Ngram)/right_idx\n",
    "count_bin = 0\n",
    "\n",
    "print(goal_bin)\n",
    "\n",
    "# 최종 데이터 Frame\n",
    "d_bin = pd.DataFrame(columns = bin6_3.columns)\n",
    "\n",
    "binutils_df = []\n",
    "# goal 에 도달할 때까지\n",
    "while True:\n",
    "    if (count_bin == goal_bin):\n",
    "            break\n",
    "    # 진행상황 살펴보기 위함\n",
    "            \n",
    "    # 랜덤 N 바이트씩 뽑음\n",
    "    # random index\n",
    "    random_idx_bin = np.random.randint(len(bin6_3)-right_idx)\n",
    "\n",
    "    if count_bin % 1000==0:\n",
    "        print(count_bin, end=' ')\n",
    "        print(random_idx_bin)\n",
    "\n",
    "    df_bin = bin6_3[random_idx_bin : random_idx_bin + right_idx]\n",
    "    \n",
    "    # 뽑은 index의 N 바이트 중에 1이 없는 경우만\n",
    "    if 1 not in df_bin['label'] and count_bin < goal_bin:\n",
    "        binutils_df.append(df_bin)\n",
    "        count_bin+=1\n",
    "\n",
    "print('완료')\n",
    "print(len(binutils_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35197\n",
      "35197\n"
     ]
    }
   ],
   "source": [
    "# True data와 False Data 같은지 체크\n",
    "print(len(binutils_df))\n",
    "print(bin6_3['label'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) False Data + True Data 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3378912, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data = pd.concat(binutils_df)\n",
    "final = pd.concat([f_data, bin6_3_Ngram])\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원핫인코딩완료\n",
      "(3378912, 257)\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터 (gcc 최적화버전 0, 1, 2, 3 one hot encoding)\n",
    "bc6_3_onehot_Ngram = pd.get_dummies(final['bin'])\n",
    "bc6_3_onehot_Ngram = pd.concat([final['label'], bc6_3_onehot_Ngram], axis=1)\n",
    "\n",
    "print('원핫인코딩완료')\n",
    "print(bc6_3_onehot_Ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3378912, 256) (3378912, 256)\n",
      "(70394, 48, 256) (70394, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터, 훈련 라벨\n",
    "x_bc6_3 = bc6_3_onehot_Ngram.iloc[:,1:].to_numpy()\n",
    "y_bc6_3 = bc6_3_onehot_Ngram['label'].to_numpy()\n",
    "print(x_bc6_3.shape, x_bc6_3.shape)\n",
    "\n",
    "x_bc6_3 = x_bc6_3.reshape(-1, right_idx, x_bc6_3.shape[1])\n",
    "y_bc6_3 = y_bc6_3.reshape(-1, right_idx, 1)\n",
    "\n",
    "print(x_bc6_3.shape, y_bc6_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70394, 48, 256) (70394, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# numpy 행, 열 섞기\n",
    "p = np.random.permutation(x_bc6_3.shape[0])\n",
    "\n",
    "x_bc6_3 = x_bc6_3[p]\n",
    "y_bc6_3 = y_bc6_3[p]\n",
    "\n",
    "print(x_bc6_3.shape, y_bc6_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) 양방향 LSTM 모델링 작업\n",
    "from tensorflow.keras import layers, models\n",
    "#from tf.keras.models import Model, Sequential\n",
    "#from tf.keras.layers import SimpleRNN, Input, Dense, LSTM\n",
    "#from tf.keras.layers import Bidirectional, TimeDistributed\n",
    "\n",
    "# 학습\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 10) # 조기종료 콜백함수 정의\n",
    "\n",
    "xInput = layers.Input(batch_shape=(None,right_idx, 256)) \n",
    "xBiLstm = layers.Bidirectional(layers.LSTM(72, return_sequences=True, stateful=False), merge_mode = 'concat')(xInput)\n",
    "xOutput = layers.TimeDistributed(layers.Dense(1, activation ='sigmoid'))(xBiLstm) # 각 스텝에서 cost가 전송되고, 오류가 다음 step으로 전송됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (8) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 48, 256)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 48, 144)           189504    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 48, 1)             145       \n",
      "=================================================================\n",
      "Total params: 189,649\n",
      "Trainable params: 189,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "======Training stage======\n",
      "Train on 49275 samples, validate on 21119 samples\n",
      "Epoch 1/500\n",
      "49275/49275 [==============================] - 287s 6ms/sample - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.0021 - val_accuracy: 0.9994\n",
      "Epoch 2/500\n",
      "49275/49275 [==============================] - 266s 5ms/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 8.6211e-04 - val_accuracy: 0.9998\n",
      "Epoch 3/500\n",
      "49275/49275 [==============================] - 261s 5ms/sample - loss: 7.6643e-04 - accuracy: 0.9998 - val_loss: 7.0456e-04 - val_accuracy: 0.9998\n",
      "Epoch 4/500\n",
      "49275/49275 [==============================] - 263s 5ms/sample - loss: 5.7191e-04 - accuracy: 0.9998 - val_loss: 5.7051e-04 - val_accuracy: 0.9999\n",
      "Epoch 5/500\n",
      "49275/49275 [==============================] - 266s 5ms/sample - loss: 4.4266e-04 - accuracy: 0.9999 - val_loss: 4.1698e-04 - val_accuracy: 0.9999\n",
      "Epoch 6/500\n",
      "49275/49275 [==============================] - 264s 5ms/sample - loss: 3.7742e-04 - accuracy: 0.9999 - val_loss: 5.1042e-04 - val_accuracy: 0.9998\n",
      "Epoch 7/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 3.1369e-04 - accuracy: 0.9999 - val_loss: 5.4833e-04 - val_accuracy: 0.9998\n",
      "Epoch 8/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 2.5366e-04 - accuracy: 0.9999 - val_loss: 3.9497e-04 - val_accuracy: 0.9999\n",
      "Epoch 9/500\n",
      "49275/49275 [==============================] - 267s 5ms/sample - loss: 2.2370e-04 - accuracy: 0.9999 - val_loss: 6.5929e-04 - val_accuracy: 0.9999\n",
      "Epoch 10/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 1.8231e-04 - accuracy: 0.9999 - val_loss: 3.4607e-04 - val_accuracy: 0.9999\n",
      "Epoch 11/500\n",
      "49275/49275 [==============================] - 266s 5ms/sample - loss: 1.6452e-04 - accuracy: 1.0000 - val_loss: 4.4474e-04 - val_accuracy: 0.9999\n",
      "Epoch 12/500\n",
      "49275/49275 [==============================] - 264s 5ms/sample - loss: 1.4813e-04 - accuracy: 1.0000 - val_loss: 2.9521e-04 - val_accuracy: 0.9999\n",
      "Epoch 13/500\n",
      "49275/49275 [==============================] - 266s 5ms/sample - loss: 1.3199e-04 - accuracy: 1.0000 - val_loss: 3.4984e-04 - val_accuracy: 0.9999\n",
      "Epoch 14/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 1.0215e-04 - accuracy: 1.0000 - val_loss: 3.6077e-04 - val_accuracy: 0.9999\n",
      "Epoch 15/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 9.6246e-05 - accuracy: 1.0000 - val_loss: 3.6201e-04 - val_accuracy: 0.9999\n",
      "Epoch 16/500\n",
      "49275/49275 [==============================] - 268s 5ms/sample - loss: 7.2005e-05 - accuracy: 1.0000 - val_loss: 5.0240e-04 - val_accuracy: 0.9999\n",
      "Epoch 17/500\n",
      "49275/49275 [==============================] - 268s 5ms/sample - loss: 6.7706e-05 - accuracy: 1.0000 - val_loss: 2.8572e-04 - val_accuracy: 0.9999\n",
      "Epoch 18/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 5.7964e-05 - accuracy: 1.0000 - val_loss: 3.5095e-04 - val_accuracy: 0.9999\n",
      "Epoch 19/500\n",
      "49275/49275 [==============================] - 267s 5ms/sample - loss: 5.2208e-05 - accuracy: 1.0000 - val_loss: 2.9911e-04 - val_accuracy: 0.9999\n",
      "Epoch 20/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 5.0427e-05 - accuracy: 1.0000 - val_loss: 3.3349e-04 - val_accuracy: 0.9999\n",
      "Epoch 21/500\n",
      "49275/49275 [==============================] - 265s 5ms/sample - loss: 4.2914e-05 - accuracy: 1.0000 - val_loss: 4.0970e-04 - val_accuracy: 0.9999\n",
      "Epoch 22/500\n",
      "49275/49275 [==============================] - 303s 6ms/sample - loss: 3.0330e-05 - accuracy: 1.0000 - val_loss: 2.9988e-04 - val_accuracy: 0.9999\n",
      "Epoch 23/500\n",
      "49275/49275 [==============================] - 329s 7ms/sample - loss: 2.5476e-05 - accuracy: 1.0000 - val_loss: 3.1382e-04 - val_accuracy: 0.9999\n",
      "Epoch 24/500\n",
      "49275/49275 [==============================] - 334s 7ms/sample - loss: 2.7735e-05 - accuracy: 1.0000 - val_loss: 3.9330e-04 - val_accuracy: 0.9999\n",
      "Epoch 25/500\n",
      "49275/49275 [==============================] - 331s 7ms/sample - loss: 2.8719e-05 - accuracy: 1.0000 - val_loss: 3.6628e-04 - val_accuracy: 0.9999\n",
      "Epoch 26/500\n",
      "49275/49275 [==============================] - 326s 7ms/sample - loss: 1.9371e-05 - accuracy: 1.0000 - val_loss: 3.8566e-04 - val_accuracy: 0.9999\n",
      "Epoch 27/500\n",
      "49275/49275 [==============================] - 235s 5ms/sample - loss: 3.2344e-05 - accuracy: 1.0000 - val_loss: 3.2519e-04 - val_accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ee84a45248>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save 완료\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Model(xInput, xOutput)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "print('======Training stage======')\n",
    "model1.fit(x_bc6_3,\n",
    "           y_bc6_3,\n",
    "           epochs = 500,\n",
    "           batch_size = 32,\n",
    "           validation_split=0.3,\n",
    "           callbacks=[early_stopping])\n",
    "\n",
    "model1.save('gcc6_bin_core_s48_h72_o3.h5')\n",
    "print('save 완료')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
