{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN 모델 N-Byte 방식 (함수정보 포함 vs 미포함 => 1:1 비율)\n",
    "\n",
    "## (1) 데이터로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28744700, 2)\n",
      "shape - (28744700, 2)\n",
      "reset_index 완료\n",
      "input data shape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bin  label\n",
       "0   47      0\n",
       "1  108      0\n",
       "2  105      0\n",
       "3   98      0\n",
       "4   47      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) 데이터로드\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 여러개 쳐도 나오게\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 파일읽기\n",
    "bin8_2 = pd.read_csv(\"../../바이너리_최종데이터_1004/gcc8/o2/o2_bincore8.csv\", index_col=0)\n",
    "print(bin8_2.shape)\n",
    "\n",
    "# reset_index (hex processing 하면서 값이 빠졌으니까 + n_gram 에서 index를 다루기 때문에)\n",
    "bin8_2.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print('shape -', bin8_2.shape)\n",
    "print('reset_index 완료')\n",
    "print('input data shape')\n",
    "bin8_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "0    28706035\n",
      "1       38665\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# (2-1) 데이터체크 1 - hex(16진수)가 256 label을 가져야 dummies 변환 가능 \n",
    "# 16진수 256개 종류가 있어서 pd.get_dummies 사용 가능.\n",
    "print(len(bin8_2['bin'].unique()))\n",
    "\n",
    "# (2-2) 데이터 체크 2 - 1, 0 비율 ==> 1이 함수의 갯수를 뜻함\n",
    "# 정답 데이터 1, 0 비율 확인  ==> 1이 함수의 갯수를 뜻함\n",
    "print(bin8_2['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) N Byte씩 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3711840\n",
      "나머지 0\n",
      "최종 길이 3711840\n",
      "bin8_2 3711840\n"
     ]
    }
   ],
   "source": [
    "idx_bin = bin8_2[bin8_2['label']==1].index  # 407, 474 ...\n",
    "ls_bin = list(idx_bin)\n",
    "\n",
    "# 최종 뽑을 행에 대한 index\n",
    "ls_idx_bin = []\n",
    "\n",
    "# n byte 자르기 방식\n",
    "left_idx, right_idx = 0, 96 # 3개씩\n",
    "\n",
    "# n byte 자르기\n",
    "for k in range(left_idx, right_idx):\n",
    "    ls_idx_bin.extend(list(idx_bin + k)) # index 형이라서 가능\n",
    "\n",
    "#ls_idx = list(set(ls_idx)) \n",
    "ls_idx_bin.sort() # 인덱스 정렬\n",
    "\n",
    "# 1차 index 해당범위 초과한 것들 없애기\n",
    "ls_idx_bin = list(filter(lambda x: x<len(bin8_2), ls_idx_bin))\n",
    "print(len(ls_idx_bin))\n",
    "\n",
    "# 2차 남은 index들 중 right_idx 나눈 나머지 없애기\n",
    "sub_bin = len(ls_idx_bin)%(right_idx)\n",
    "print('나머지', sub_bin)\n",
    "\n",
    "ls_idx_bin = ls_idx_bin[:len(ls_idx_bin)-sub_bin]\n",
    "print('최종 길이', len(ls_idx_bin))\n",
    "\n",
    "print('bin8_2', len(ls_idx_bin))\n",
    "\n",
    "# loc 로 수정필요\n",
    "bin8_2_Ngram = bin8_2.loc[ls_idx_bin,:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) false data 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38665.0\n",
      "0 5077538\n",
      "1000 24836228\n",
      "2000 14665030\n",
      "3000 13421938\n",
      "4000 15288517\n",
      "5000 18963844\n",
      "6000 27051253\n",
      "7000 10048783\n",
      "8000 18184106\n",
      "9000 925246\n",
      "10000 19167748\n",
      "11000 18724740\n",
      "12000 3116858\n",
      "13000 11371396\n",
      "14000 10259174\n",
      "15000 19612179\n",
      "16000 19893913\n",
      "17000 24672583\n",
      "18000 14241178\n",
      "19000 14697852\n",
      "20000 8216572\n",
      "21000 10686512\n",
      "22000 4540349\n",
      "23000 24606460\n",
      "24000 17222849\n",
      "25000 7893218\n",
      "26000 18972460\n",
      "27000 27328561\n",
      "28000 22894878\n",
      "29000 20074998\n",
      "30000 15710127\n",
      "31000 28067022\n",
      "32000 18567174\n",
      "33000 22707478\n",
      "34000 16271767\n",
      "35000 1708035\n",
      "36000 13233006\n",
      "37000 25626437\n",
      "38000 5124253\n",
      "완료\n",
      "38665\n"
     ]
    }
   ],
   "source": [
    "# false data 만들기 - False 데이터 랜덤 생성\n",
    "\n",
    "# 목표치\n",
    "goal_bin = len(bin8_2_Ngram)/right_idx\n",
    "count_bin = 0\n",
    "\n",
    "print(goal_bin)\n",
    "\n",
    "# 최종 데이터 Frame\n",
    "d_bin = pd.DataFrame(columns = bin8_2.columns)\n",
    "\n",
    "binutils_df = []\n",
    "# goal 에 도달할 때까지\n",
    "while True:\n",
    "    if (count_bin == goal_bin):\n",
    "            break\n",
    "    # 진행상황 살펴보기 위함\n",
    "            \n",
    "    # 랜덤 N 바이트씩 뽑음\n",
    "    # random index\n",
    "    random_idx_bin = np.random.randint(len(bin8_2)-right_idx)\n",
    "\n",
    "    if count_bin % 1000==0:\n",
    "        print(count_bin, end=' ')\n",
    "        print(random_idx_bin)\n",
    "\n",
    "    df_bin = bin8_2[random_idx_bin : random_idx_bin + right_idx]\n",
    "    \n",
    "    # 뽑은 index의 N 바이트 중에 1이 없는 경우만\n",
    "    if 1 not in df_bin['label'] and count_bin < goal_bin:\n",
    "        binutils_df.append(df_bin)\n",
    "        count_bin+=1\n",
    "\n",
    "print('완료')\n",
    "print(len(binutils_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38665\n",
      "38665\n"
     ]
    }
   ],
   "source": [
    "# True data와 False Data 같은지 체크\n",
    "print(len(binutils_df))\n",
    "print(bin8_2['label'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) False Data + True Data 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7423680, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_data = pd.concat(binutils_df)\n",
    "final = pd.concat([f_data, bin8_2_Ngram])\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원핫인코딩완료\n",
      "(7423680, 257)\n"
     ]
    }
   ],
   "source": [
    "# 훈련데이터 (gcc 최적화버전 0, 1, 2, 3 one hot encoding)\n",
    "bc8_2_onehot_Ngram = pd.get_dummies(final['bin'])\n",
    "bc8_2_onehot_Ngram = pd.concat([final['label'], bc8_2_onehot_Ngram], axis=1)\n",
    "\n",
    "print('원핫인코딩완료')\n",
    "print(bc8_2_onehot_Ngram.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7423680, 256) (7423680, 256)\n",
      "(77330, 96, 256) (77330, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터, 훈련 라벨\n",
    "x_bc8_2 = bc8_2_onehot_Ngram.iloc[:,1:].to_numpy()\n",
    "y_bc8_2 = bc8_2_onehot_Ngram['label'].to_numpy()\n",
    "print(x_bc8_2.shape, x_bc8_2.shape)\n",
    "\n",
    "x_bc8_2 = x_bc8_2.reshape(-1, right_idx, x_bc8_2.shape[1])\n",
    "y_bc8_2 = y_bc8_2.reshape(-1, right_idx, 1)\n",
    "\n",
    "print(x_bc8_2.shape, y_bc8_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77330, 96, 256) (77330, 96, 1)\n"
     ]
    }
   ],
   "source": [
    "# numpy 행, 열 섞기\n",
    "p = np.random.permutation(x_bc8_2.shape[0])\n",
    "\n",
    "x_bc8_2 = x_bc8_2[p]\n",
    "y_bc8_2 = y_bc8_2[p]\n",
    "\n",
    "print(x_bc8_2.shape, y_bc8_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x_bc8_2', x_bc8_2)\n",
    "np.save('y_bc8_2', y_bc8_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (10) 양방향 LSTM 모델링 작업\n",
    "from tensorflow.keras import layers, models\n",
    "#from tf.keras.models import Model, Sequential\n",
    "#from tf.keras.layers import SimpleRNN, Input, Dense, LSTM\n",
    "#from tf.keras.layers import Bidirectional, TimeDistributed\n",
    "\n",
    "# 학습\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience = 10) # 조기종료 콜백함수 정의\n",
    "\n",
    "xInput = layers.Input(batch_shape=(None,right_idx, 256)) \n",
    "xBiLstm = layers.Bidirectional(layers.LSTM(144, return_sequences=True, stateful=False), merge_mode = 'concat')(xInput)\n",
    "xOutput = layers.TimeDistributed(layers.Dense(1, activation ='sigmoid'))(xBiLstm) # 각 스텝에서 cost가 전송되고, 오류가 다음 step으로 전송됨."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (8) 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 96, 256)]         0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 96, 288)           461952    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 96, 1)             289       \n",
      "=================================================================\n",
      "Total params: 462,241\n",
      "Trainable params: 462,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "======Training stage======\n",
      "Train on 54131 samples, validate on 23199 samples\n",
      "Epoch 1/500\n",
      "54131/54131 [==============================] - 47s 874us/sample - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.0030 - val_accuracy: 0.9991\n",
      "Epoch 2/500\n",
      "54131/54131 [==============================] - 33s 617us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 3/500\n",
      "54131/54131 [==============================] - 33s 609us/sample - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 4/500\n",
      "54131/54131 [==============================] - 33s 608us/sample - loss: 9.3291e-04 - accuracy: 0.9998 - val_loss: 0.0010 - val_accuracy: 0.9997\n",
      "Epoch 5/500\n",
      "54131/54131 [==============================] - 33s 609us/sample - loss: 6.7282e-04 - accuracy: 0.9998 - val_loss: 9.3806e-04 - val_accuracy: 0.9998\n",
      "Epoch 6/500\n",
      "54131/54131 [==============================] - 33s 613us/sample - loss: 5.7423e-04 - accuracy: 0.9999 - val_loss: 6.6173e-04 - val_accuracy: 0.9998\n",
      "Epoch 7/500\n",
      "54131/54131 [==============================] - 33s 610us/sample - loss: 4.0509e-04 - accuracy: 0.9999 - val_loss: 7.7032e-04 - val_accuracy: 0.9998\n",
      "Epoch 8/500\n",
      "54131/54131 [==============================] - 33s 610us/sample - loss: 3.8596e-04 - accuracy: 0.9999 - val_loss: 7.0700e-04 - val_accuracy: 0.9998\n",
      "Epoch 9/500\n",
      "54131/54131 [==============================] - 33s 614us/sample - loss: 3.3189e-04 - accuracy: 0.9999 - val_loss: 5.8704e-04 - val_accuracy: 0.9998\n",
      "Epoch 10/500\n",
      "54131/54131 [==============================] - 33s 609us/sample - loss: 2.7927e-04 - accuracy: 0.9999 - val_loss: 5.2002e-04 - val_accuracy: 0.9999\n",
      "Epoch 11/500\n",
      "54131/54131 [==============================] - 33s 611us/sample - loss: 2.6022e-04 - accuracy: 0.9999 - val_loss: 4.9848e-04 - val_accuracy: 0.9999\n",
      "Epoch 12/500\n",
      "54131/54131 [==============================] - 33s 610us/sample - loss: 2.2409e-04 - accuracy: 0.9999 - val_loss: 5.3647e-04 - val_accuracy: 0.9999\n",
      "Epoch 13/500\n",
      "54131/54131 [==============================] - 33s 617us/sample - loss: 1.7390e-04 - accuracy: 1.0000 - val_loss: 5.4824e-04 - val_accuracy: 0.9999\n",
      "Epoch 14/500\n",
      "54131/54131 [==============================] - 33s 613us/sample - loss: 1.7964e-04 - accuracy: 1.0000 - val_loss: 4.4905e-04 - val_accuracy: 0.9999\n",
      "Epoch 15/500\n",
      "54131/54131 [==============================] - 33s 613us/sample - loss: 1.4250e-04 - accuracy: 1.0000 - val_loss: 6.6231e-04 - val_accuracy: 0.9999\n",
      "Epoch 16/500\n",
      "54131/54131 [==============================] - 33s 614us/sample - loss: 1.1769e-04 - accuracy: 1.0000 - val_loss: 5.7884e-04 - val_accuracy: 0.9999\n",
      "Epoch 17/500\n",
      "54131/54131 [==============================] - 33s 617us/sample - loss: 1.4660e-04 - accuracy: 1.0000 - val_loss: 4.5264e-04 - val_accuracy: 0.9999\n",
      "Epoch 18/500\n",
      "54131/54131 [==============================] - 33s 614us/sample - loss: 9.4453e-05 - accuracy: 1.0000 - val_loss: 4.7982e-04 - val_accuracy: 0.9999\n",
      "Epoch 19/500\n",
      "54131/54131 [==============================] - 33s 613us/sample - loss: 6.9587e-05 - accuracy: 1.0000 - val_loss: 5.4517e-04 - val_accuracy: 0.9999\n",
      "Epoch 20/500\n",
      "54131/54131 [==============================] - 33s 613us/sample - loss: 9.2346e-05 - accuracy: 1.0000 - val_loss: 5.4545e-04 - val_accuracy: 0.9999\n",
      "Epoch 21/500\n",
      "54131/54131 [==============================] - 33s 617us/sample - loss: 3.9407e-05 - accuracy: 1.0000 - val_loss: 5.4681e-04 - val_accuracy: 0.9999\n",
      "Epoch 22/500\n",
      "54131/54131 [==============================] - 33s 617us/sample - loss: 6.3574e-05 - accuracy: 1.0000 - val_loss: 5.3849e-04 - val_accuracy: 0.9999\n",
      "Epoch 23/500\n",
      "54131/54131 [==============================] - 33s 617us/sample - loss: 7.0982e-05 - accuracy: 1.0000 - val_loss: 5.4447e-04 - val_accuracy: 0.9999\n",
      "Epoch 24/500\n",
      "54131/54131 [==============================] - 33s 616us/sample - loss: 3.2968e-05 - accuracy: 1.0000 - val_loss: 5.3714e-04 - val_accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2cf588f7288>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "걸린시간: 813.6065378189087\n",
      "save 완료\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Model(xInput, xOutput)\n",
    "model1.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model1.summary()\n",
    "import time\n",
    "print('======Training stage======')\n",
    "starttime = time.time()\n",
    "\n",
    "model1.fit(x_bc8_2,\n",
    "           y_bc8_2,\n",
    "           epochs = 500,\n",
    "           batch_size = 32,\n",
    "           validation_split=0.3,\n",
    "           callbacks=[early_stopping])\n",
    "\n",
    "endtime = time.time()\n",
    "print('걸린시간:', endtime - starttime)\n",
    "\n",
    "model1.save('gcc8_bin_core_s96_h144_o2.h5')\n",
    "print('save 완료')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
